"""
AI ìš”ì•½ ëª¨ë“ˆ
Gemini 2.0 Flash ì‚¬ìš© (ë¬´ë£Œ)
"""
import os
import google.generativeai as genai


class GeminiSummarizer:
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            print("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.model = None
        else:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
            print("âœ… Gemini 2.0 Flash ì´ˆê¸°í™” ì™„ë£Œ")

    def summarize(self, video_info: dict, transcript: str, prompt_key: str = 'archive') -> str:
        """
        Geminië¡œ ì˜ìƒ ìš”ì•½
        """
        if not self.model:
            return "âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # ìë§‰ ê¸¸ì´ ì œí•œ (í† í° ì ˆì•½)
        max_chars = 24000  # ì•½ 8K tokens
        if len(transcript) > max_chars:
            transcript = transcript[:max_chars] + "\n\n...(ì´í•˜ ìƒëµ)"
            print(f"âš ï¸ ìë§‰ì´ ë„ˆë¬´ ê¸¸ì–´ {max_chars}ìë¡œ ì œí•œí–ˆìŠµë‹ˆë‹¤.")

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompts = {
            'archive': """ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ì •ì œ ë° ì•„ì¹´ì´ë¸Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ìš” ì‘ì—…:
1. ì˜ìƒ ìë§‰/ì„¤ëª…ì„ í•œê¸€ë¡œ ì •ì œ (ì˜ì–´ëŠ” ë²ˆì—­ í›„ ì •ì œ)
2. 1000ì¤„ ì´ë‚´ë¡œ ì •ì œ ë° ì •ë¦¬
3. ì¼ëª©ìš”ì—°í•˜ê²Œ êµ¬ì¡°í™”í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
4. í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì—¬ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶œë ¥ í˜•ì‹:
# ì œëª©

## í•µì‹¬ ìš”ì•½
- ì£¼ìš” í¬ì¸íŠ¸ 1
- ì£¼ìš” í¬ì¸íŠ¸ 2
- ...

## ìƒì„¸ ë‚´ìš©
(êµ¬ì¡°í™”ëœ ë³¸ë¬¸)

## ì£¼ìš” ì¸ì‚¬ì´íŠ¸
- ì¸ì‚¬ì´íŠ¸ 1
- ì¸ì‚¬ì´íŠ¸ 2
""",
            'agent-reference': """ë‹¹ì‹ ì€ AI ì—ì´ì „íŠ¸ ì°¸ê³ ìë£Œ ë²ˆì—­ ë° ì •ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ìš” ì‘ì—…:
1. ì˜ìƒ ë‚´ìš©ì„ í•œê¸€ë¡œ ë²ˆì—­ ë° ì •ì œ
2. AI ì—ì´ì „íŠ¸ ê°œë°œ/í™œìš©ì— ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
3. ì‹¤ë¬´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ì •ë³´ ìš°ì„  ì •ë¦¬
4. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ì¶œë ¥ í˜•ì‹:
# AI ì—ì´ì „íŠ¸ ê´€ë ¨ í•µì‹¬ ë‚´ìš©

## ì£¼ìš” ê°œë…
- ê°œë… 1
- ê°œë… 2

## êµ¬í˜„ ë°©ë²•
(ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ë‚´ìš©)

## í™œìš© ì‚¬ë¡€
- ì‚¬ë¡€ 1
- ì‚¬ë¡€ 2

## ì°¸ê³  ì‚¬í•­
(ì¶”ê°€ ì •ë³´)
"""
        }

        system_prompt = system_prompts.get(prompt_key, system_prompts['archive'])

        prompt = f"""{system_prompt}

---

ì˜ìƒ ì œëª©: {video_info['title']}
ì±„ë„: {video_info['channel']}
ê¸¸ì´: {video_info['duration']}

ìë§‰ ë‚´ìš©:
{transcript}

---

ìœ„ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì •ì œí•´ì£¼ì„¸ìš”.
"""

        try:
            print("ğŸ¤– Gemini AI ìš”ì•½ ì‹œì‘...")
            response = self.model.generate_content(prompt)
            summary = response.text

            print(f"âœ… AI ìš”ì•½ ì™„ë£Œ: {len(summary)} ê¸€ì")
            return summary

        except Exception as e:
            print(f"âŒ Gemini API ì˜¤ë¥˜: {e}")
            return f"âŒ AI ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# Claude Haiku ë°±ì—… ì˜µì…˜ (ìœ ë£Œì§€ë§Œ ì €ë ´)
class ClaudeSummarizer:
    def __init__(self, model_name: str = 'claude-3-haiku-20240307'):
        import anthropic
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            print("âš ï¸ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.client = None
        else:
            self.client = anthropic.Anthropic(api_key=self.api_key)
            self.model_name = model_name
            print(f"âœ… Claude {model_name} ì´ˆê¸°í™” ì™„ë£Œ")

    def summarize(self, video_info: dict, transcript: str, prompt_key: str = 'archive', max_tokens: int = 2048) -> str:
        """Claudeë¡œ ì˜ìƒ ìš”ì•½"""
        if not self.client:
            return "âŒ Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # ìë§‰ ê¸¸ì´ ì œí•œ
        max_chars = 24000
        if len(transcript) > max_chars:
            transcript = transcript[:max_chars] + "\n\n...(ì´í•˜ ìƒëµ)"

        system_prompts = {
            'archive': """ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ì •ì œ ë° ì•„ì¹´ì´ë¸Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì˜ìƒ ìë§‰ì„ í•œê¸€ë¡œ ì •ì œí•˜ê³  1000ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.""",
            'agent-reference': """ë‹¹ì‹ ì€ AI ì—ì´ì „íŠ¸ ì°¸ê³ ìë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
AI ì—ì´ì „íŠ¸ ê°œë°œ/í™œìš©ì— ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
        }

        system_prompt = system_prompts.get(prompt_key, system_prompts['archive'])

        try:
            print(f"ğŸ¤– Claude AI ìš”ì•½ ì‹œì‘ (ëª¨ë¸: {self.model_name})...")

            message = self.client.messages.create(
                model=self.model_name,
                max_tokens=max_tokens,
                system=system_prompt,
                messages=[{
                    "role": "user",
                    "content": f"""ì˜ìƒ ì œëª©: {video_info['title']}
ì±„ë„: {video_info['channel']}

ìë§‰:
{transcript}

ìœ„ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì •ì œí•´ì£¼ì„¸ìš”."""
                }]
            )

            summary = message.content[0].text
            print(f"âœ… Claude ìš”ì•½ ì™„ë£Œ: {len(summary)} ê¸€ì")
            return summary

        except Exception as e:
            print(f"âŒ Claude API ì˜¤ë¥˜: {e}")
            return f"âŒ AI ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    from dotenv import load_dotenv
    load_dotenv()

    # Gemini í…ŒìŠ¤íŠ¸
    summarizer = GeminiSummarizer()

    test_video_info = {
        'title': 'Test Video',
        'channel': 'Test Channel',
        'duration': '10:00'
    }

    test_transcript = "This is a test transcript. " * 100

    summary = summarizer.summarize(test_video_info, test_transcript)
    print(f"\nìš”ì•½ ê²°ê³¼:\n{summary[:500]}...")
